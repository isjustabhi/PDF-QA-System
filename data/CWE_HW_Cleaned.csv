Description,Extended Description,Detection Methods,Potential Mitigations
"Discrepancies can take many forms, and variations may be detectable in timing, control flow, communications such as replies or requests, or general behavior. These discrepancies can reveal information about the product's operation or internal state to an unauthorized actor. In some cases, discrepancies can be used by attackers to form a side channel.",::NATURE:ChildOf:CWE ID:200:VIEW ID:1000:ORDINAL:Primary::NATURE:ChildOf:CWE ID:200:VIEW ID:1003:ORDINAL:Primary::,"::PHASE:Architecture and Design:STRATEGY:Separation of Privilege:DESCRIPTION:Compartmentalize the system to have safe areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area. Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.::PHASE:Implementation:DESCRIPTION:Ensure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success. If errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files. Avoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.::","::REFERENCE:CVE-2020-8695:DESCRIPTION:Observable discrepancy in the RAPL interface for some Intel processors allows information disclosure.:LINK:https://www.cve.org/CVERecord?id=CVE-2020-8695::REFERENCE:CVE-2019-14353:DESCRIPTION:Crypto hardware wallet's power consumption relates to total number of pixels illuminated, creating a side channel in the USB connection that allows attackers to determine secrets displayed such as PIN numbers and passwords:LINK:https://www.cve.org/CVERecord?id=CVE-2019-14353::REFERENCE:CVE-2019-10071:DESCRIPTION:Java-oriented framework compares HMAC signatures using String.equals() instead of a constant-time algorithm, causing timing discrepancies:LINK:https://www.cve.org/CVERecord?id=CVE-2019-10071::REFERENCE:CVE-2002-2094:DESCRIPTION:This, and others, use .. attacks and monitor error responses, so there is overlap with directory traversal.:LINK:https://www.cve.org/CVERecord?id=CVE-2002-2094::REFERENCE:CVE-2001-1483:DESCRIPTION:Enumeration of valid usernames based on inconsistent responses:LINK:https://www.cve.org/CVERecord?id=CVE-2001-1483::REFERENCE:CVE-2001-1528:DESCRIPTION:Account number enumeration via inconsistent responses.:LINK:https://www.cve.org/CVERecord?id=CVE-2001-1528::REFERENCE:CVE-2004-2150:DESCRIPTION:User enumeration via discrepancies in error messages.:LINK:https://www.cve.org/CVERecord?id=CVE-2004-2150::REFERENCE:CVE-2005-1650:DESCRIPTION:User enumeration via discrepancies in error messages.:LINK:https://www.cve.org/CVERecord?id=CVE-2005-1650::REFERENCE:CVE-2004-0294:DESCRIPTION:Bulletin Board displays different error messages when a user exists or not, which makes it easier for remote attackers to identify valid users and conduct a brute force password guessing attack.:LINK:https://www.cve.org/CVERecord?id=CVE-2004-0294::REFERENCE:CVE-2004-0243:DESCRIPTION:Operating System, when direct remote login is disabled, displays a different message if the password is correct, which allows remote attackers to guess the password via brute force methods.:LINK:https://www.cve.org/CVERecord?id=CVE-2004-0243::REFERENCE:CVE-2002-0514:DESCRIPTION:Product allows remote attackers to determine if a port is being filtered because the response packet TTL is different than the default TTL.:LINK:https://www.cve.org/CVERecord?id=CVE-2002-0514::REFERENCE:CVE-2002-0515:DESCRIPTION:Product sets a different TTL when a port is being filtered than when it is not being filtered, which allows remote attackers to identify filtered ports by comparing TTLs.:LINK:https://www.cve.org/CVERecord?id=CVE-2002-0515::REFERENCE:CVE-2002-0208:DESCRIPTION:Product modifies TCP/IP stack and ICMP error messages in unusual ways that show the product is in use.:LINK:https://www.cve.org/CVERecord?id=CVE-2002-0208::REFERENCE:CVE-2004-2252:DESCRIPTION:Behavioral infoleak by responding to SYN-FIN packets.:LINK:https://www.cve.org/CVERecord?id=CVE-2004-2252::REFERENCE:CVE-2001-1387:DESCRIPTION:Product may generate different responses than specified by the administrator, possibly leading to an information leak.:LINK:https://www.cve.org/CVERecord?id=CVE-2001-1387::REFERENCE:CVE-2004-0778:DESCRIPTION:Version control system allows remote attackers to determine the existence of arbitrary files and directories via the -X command for an alternate history file, which causes different error messages to be returned.:LINK:https://www.cve.org/CVERecord?id=CVE-2004-0778::REFERENCE:CVE-2004-1428:DESCRIPTION:FTP server generates an error message if the user name does not exist instead of prompting for a password, which allows remote attackers to determine valid usernames.:LINK:https://www.cve.org/CVERecord?id=CVE-2004-1428::REFERENCE:CVE-2003-0078:DESCRIPTION:SSL implementation does not perform a MAC computation if an incorrect block cipher padding is used, which causes an information leak (timing discrepancy) that may make it easier to launch cryptographic attacks that rely on distinguishing between padding and MAC verification errors, possibly leading to extraction of the original plaintext, aka the Vaudenay timing attack.:LINK:https://www.cve.org/CVERecord?id=CVE-2003-0078::REFERENCE:CVE-2000-1117:DESCRIPTION:Virtual machine allows malicious web site operators to determine the existence of files on the client by measuring delays in the execution of the getSystemResource method.:LINK:https://www.cve.org/CVERecord?id=CVE-2000-1117::REFERENCE:CVE-2003-0637:DESCRIPTION:Product uses a shorter timeout for a non-existent user than a valid user, which makes it easier for remote attackers to guess usernames and conduct brute force password guessing.:LINK:https://www.cve.org/CVERecord?id=CVE-2003-0637::REFERENCE:CVE-2003-0190:DESCRIPTION:Product immediately sends an error message when a user does not exist, which allows remote attackers to determine valid usernames via a timing attack.:LINK:https://www.cve.org/CVERecord?id=CVE-2003-0190::REFERENCE:CVE-2004-1602:DESCRIPTION:FTP server responds in a different amount of time when a given username exists, which allows remote attackers to identify valid usernames by timing the server response.:LINK:https://www.cve.org/CVERecord?id=CVE-2004-1602::REFERENCE:CVE-2005-0918:DESCRIPTION:Browser allows remote attackers to determine the existence of arbitrary files by setting the src property to the target filename and using Javascript to determine if the web page immediately stops loading, which indicates whether the file exists or not.:LINK:https://www.cve.org/CVERecord?id=CVE-2005-0918::"
"When resources are released, they can be made available for reuse. For example, after memory is de-allocated, an operating system may make the memory available to another process, or disk space may be reallocated when a file is deleted. As removing information requires time and additional resources, operating systems do not usually clear the previously written information. Even when the resource is reused by the same process, this weakness can arise when new data is not as large as the old data, which leaves portions of the old data still available. Equivalent errors can occur in other situations where the length of data is variable but the associated data structure is not. If memory is not cleared after use, the information may be read by less trustworthy parties when the memory is reallocated. This weakness can apply in hardware, such as when a device or system switches between power, sleep, or debug states during normal operation, or when execution changes to different users or privilege levels.",::NATURE:ChildOf:CWE ID:459:VIEW ID:1000:ORDINAL:Primary::NATURE:ChildOf:CWE ID:212:VIEW ID:1000::NATURE:CanPrecede:CWE ID:201:VIEW ID:1000::,"::PHASE:Architecture and Design Implementation:DESCRIPTION:During critical state transitions, information not needed in the next state should be removed or overwritten with fixed patterns (such as all 0's) or random data, before the transition to the next state.:EFFECTIVENESS:High::PHASE:Architecture and Design Implementation:DESCRIPTION:When releasing, de-allocating, or deleting a resource, overwrite its data and relevant metadata with fixed patterns or random data. Be cautious about complex resource types whose underlying representation might be non-contiguous or change at a low level, such as how a file might be split into different chunks on a file system, even though logical file positions are contiguous at the application layer. Such resource types might require invocation of special modes or APIs to tell the underlying operating system to perform the necessary clearing, such as SDelete (Secure Delete) on Windows, although the appropriate functionality might not be available at the application layer.:EFFECTIVENESS:High::","::REFERENCE:CVE-2019-3733:DESCRIPTION:Cryptography library does not clear heap memory before release:LINK:https://www.cve.org/CVERecord?id=CVE-2019-3733::REFERENCE:CVE-2003-0001:DESCRIPTION:Ethernet NIC drivers do not pad frames with null bytes, leading to infoleak from malformed packets.:LINK:https://www.cve.org/CVERecord?id=CVE-2003-0001::REFERENCE:CVE-2003-0291:DESCRIPTION:router does not clear information from DHCP packets that have been previously used:LINK:https://www.cve.org/CVERecord?id=CVE-2003-0291::REFERENCE:CVE-2005-1406:DESCRIPTION:Products do not fully clear memory buffers when less data is stored into the buffer than previous.:LINK:https://www.cve.org/CVERecord?id=CVE-2005-1406::REFERENCE:CVE-2005-1858:DESCRIPTION:Products do not fully clear memory buffers when less data is stored into the buffer than previous.:LINK:https://www.cve.org/CVERecord?id=CVE-2005-1858::REFERENCE:CVE-2005-3180:DESCRIPTION:Products do not fully clear memory buffers when less data is stored into the buffer than previous.:LINK:https://www.cve.org/CVERecord?id=CVE-2005-3180::REFERENCE:CVE-2005-3276:DESCRIPTION:Product does not clear a data structure before writing to part of it, yielding information leak of previously used memory.:LINK:https://www.cve.org/CVERecord?id=CVE-2005-3276::REFERENCE:CVE-2002-2077:DESCRIPTION:Memory not properly cleared before reuse.:LINK:https://www.cve.org/CVERecord?id=CVE-2002-2077::"
N/A,::NATURE:ChildOf:CWE ID:732:VIEW ID:1000:ORDINAL:Primary::NATURE:ChildOf:CWE ID:732:VIEW ID:1003:ORDINAL:Primary::,"::PHASE:Architecture and Design Operation:DESCRIPTION:The architecture needs to access and modification attributes for files to only those users who actually require those actions.::PHASE:Architecture and Design:STRATEGY:Separation of Privilege:DESCRIPTION:Compartmentalize the system to have safe areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area. Ensure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.::",::REFERENCE:CVE-2005-1941:DESCRIPTION:Executables installed world-writable.:LINK:https://www.cve.org/CVERecord?id=CVE-2005-1941::REFERENCE:CVE-2002-1713:DESCRIPTION:Home directories installed world-readable.:LINK:https://www.cve.org/CVERecord?id=CVE-2002-1713::REFERENCE:CVE-2001-1550:DESCRIPTION:World-writable log files allow information loss; world-readable file has cleartext passwords.:LINK:https://www.cve.org/CVERecord?id=CVE-2001-1550::REFERENCE:CVE-2002-1711:DESCRIPTION:World-readable directory.:LINK:https://www.cve.org/CVERecord?id=CVE-2002-1711::REFERENCE:CVE-2002-1844:DESCRIPTION:Windows product uses insecure permissions when installing on Solaris (genesis: port error).:LINK:https://www.cve.org/CVERecord?id=CVE-2002-1844::REFERENCE:CVE-2001-0497:DESCRIPTION:Insecure permissions for a shared secret key file. Overlaps cryptographic problem.:LINK:https://www.cve.org/CVERecord?id=CVE-2001-0497::REFERENCE:CVE-1999-0426:DESCRIPTION:Default permissions of a device allow IP spoofing.:LINK:https://www.cve.org/CVERecord?id=CVE-1999-0426::
N/A,::NATURE:ChildOf:CWE ID:311:VIEW ID:1000:ORDINAL:Primary::NATURE:ChildOf:CWE ID:311:VIEW ID:1003:ORDINAL:Primary::,"::PHASE:Architecture and Design:DESCRIPTION:Before transmitting, encrypt the data using reliable, confidentiality-protecting cryptographic protocols.::PHASE:Implementation:DESCRIPTION:When using web applications with SSL, use SSL for the entire session from login to logout, not just for the initial login page.::PHASE:Implementation:DESCRIPTION:When designing hardware platforms, ensure that approved encryption algorithms (such as those recommended by NIST) protect paths from security critical data to trusted user applications.::PHASE:Testing:DESCRIPTION:Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.::PHASE:Operation:DESCRIPTION:Configure servers to use encrypted channels for communication, which may include SSL or other secure protocols.::","::REFERENCE:CVE-2022-29519:DESCRIPTION:Programmable Logic Controller (PLC) sends sensitive information in plaintext, including passwords and session tokens.:LINK:https://www.cve.org/CVERecord?id=CVE-2022-29519::REFERENCE:CVE-2022-30312:DESCRIPTION:Building Controller uses a protocol that transmits authentication credentials in plaintext.:LINK:https://www.cve.org/CVERecord?id=CVE-2022-30312::REFERENCE:CVE-2022-31204:DESCRIPTION:Programmable Logic Controller (PLC) sends password in plaintext.:LINK:https://www.cve.org/CVERecord?id=CVE-2022-31204::REFERENCE:CVE-2002-1949:DESCRIPTION:Passwords transmitted in cleartext.:LINK:https://www.cve.org/CVERecord?id=CVE-2002-1949::REFERENCE:CVE-2008-4122:DESCRIPTION:Chain: Use of HTTPS cookie without secure flag causes it to be transmitted across unencrypted HTTP.:LINK:https://www.cve.org/CVERecord?id=CVE-2008-4122::REFERENCE:CVE-2008-3289:DESCRIPTION:Product sends password hash in cleartext in violation of intended policy.:LINK:https://www.cve.org/CVERecord?id=CVE-2008-3289::REFERENCE:CVE-2008-4390:DESCRIPTION:Remote management feature sends sensitive information including passwords in cleartext.:LINK:https://www.cve.org/CVERecord?id=CVE-2008-4390::REFERENCE:CVE-2007-5626:DESCRIPTION:Backup routine sends password in cleartext in email.:LINK:https://www.cve.org/CVERecord?id=CVE-2007-5626::REFERENCE:CVE-2004-1852:DESCRIPTION:Product transmits Blowfish encryption key in cleartext.:LINK:https://www.cve.org/CVERecord?id=CVE-2004-1852::REFERENCE:CVE-2008-0374:DESCRIPTION:Printer sends configuration information, including administrative password, in cleartext.:LINK:https://www.cve.org/CVERecord?id=CVE-2008-0374::REFERENCE:CVE-2007-4961:DESCRIPTION:Chain: cleartext transmission of the MD5 hash of password enables attacks against a server that is susceptible to replay (CWE-294).:LINK:https://www.cve.org/CVERecord?id=CVE-2007-4961::REFERENCE:CVE-2007-4786:DESCRIPTION:Product sends passwords in cleartext to a log server.:LINK:https://www.cve.org/CVERecord?id=CVE-2007-4786::REFERENCE:CVE-2005-3140:DESCRIPTION:Product sends file with cleartext passwords in e-mail message intended for diagnostic purposes.:LINK:https://www.cve.org/CVERecord?id=CVE-2005-3140::"
N/A,::NATURE:ChildOf:CWE ID:573:VIEW ID:1000:ORDINAL:Primary::NATURE:PeerOf:CWE ID:358:VIEW ID:1000::,N/A,::REFERENCE:CVE-2001-1585:DESCRIPTION:Missing challenge-response step allows authentication bypass using public key.:LINK:https://www.cve.org/CVERecord?id=CVE-2001-1585::
N/A,::NATURE:ChildOf:CWE ID:684:VIEW ID:1000:ORDINAL:Primary::,N/A,"::REFERENCE:CVE-2003-0187:DESCRIPTION:Program uses large timeouts on unconfirmed connections resulting from inconsistency in linked lists implementations.:LINK:https://www.cve.org/CVERecord?id=CVE-2003-0187::REFERENCE:CVE-2003-0465:DESCRIPTION:strncpy in Linux kernel acts different than libc on x86, leading to expected behavior difference - sort of a multiple interpretation error?:LINK:https://www.cve.org/CVERecord?id=CVE-2003-0465::REFERENCE:CVE-2005-3265:DESCRIPTION:Buffer overflow in product stems the use of a third party library function that is expected to have internal protection against overflows, but doesn't.:LINK:https://www.cve.org/CVERecord?id=CVE-2005-3265::"
"If an attacker cannot directly contact a target, but the product has access to the target, then the attacker can send a request to the product and have it be forwarded to the target. The request would appear to be coming from the product's system, not the attacker's system. As a result, the attacker can bypass access controls (such as firewalls) or hide the source of malicious requests, since the requests would not be coming directly from the attacker. Since proxy functionality and message-forwarding often serve a legitimate purpose, this issue only becomes a vulnerability when: The product runs with different privileges or on a different system, or otherwise has different levels of access than the upstream component; The attacker is prevented from making the request directly to the target; and The attacker can create a request that the proxy does not explicitly intend to be forwarded on the behalf of the requester. Such a request might point to an unexpected hostname, port number, hardware IP, or service. Or, the request might be sent to an allowed service, but the request could contain disallowed directives, commands, or resources.",::NATURE:ChildOf:CWE ID:610:VIEW ID:1000:ORDINAL:Primary::NATURE:CanPrecede:CWE ID:668:VIEW ID:1000::,"::PHASE:Architecture and Design:DESCRIPTION:Enforce the use of strong mutual authentication mechanism between the two parties.::PHASE:Architecture and Design:DESCRIPTION:Whenever a product is an intermediary or proxy for transactions between two other components, the proxy core should not drop the identity of the initiator of the transaction. The immutability of the identity of the initiator must be maintained and should be forwarded all the way to the target.::","::REFERENCE:CVE-1999-0017:DESCRIPTION:FTP bounce attack. The design of the protocol allows an attacker to modify the PORT command to cause the FTP server to connect to other machines besides the attacker's.:LINK:https://www.cve.org/CVERecord?id=CVE-1999-0017::REFERENCE:CVE-1999-0168:DESCRIPTION:RPC portmapper could redirect service requests from an attacker to another entity, which thinks the requests came from the portmapper.:LINK:https://www.cve.org/CVERecord?id=CVE-1999-0168::REFERENCE:CVE-2005-0315:DESCRIPTION:FTP server does not ensure that the IP address in a PORT command is the same as the FTP user's session, allowing port scanning by proxy.:LINK:https://www.cve.org/CVERecord?id=CVE-2005-0315::REFERENCE:CVE-2002-1484:DESCRIPTION:Web server allows attackers to request a URL from another server, including other ports, which allows proxied scanning.:LINK:https://www.cve.org/CVERecord?id=CVE-2002-1484::REFERENCE:CVE-2004-2061:DESCRIPTION:CGI script accepts and retrieves incoming URLs.:LINK:https://www.cve.org/CVERecord?id=CVE-2004-2061::REFERENCE:CVE-2001-1484:DESCRIPTION:Bounce attack allows access to TFTP from trusted side.:LINK:https://www.cve.org/CVERecord?id=CVE-2001-1484::REFERENCE:CVE-2010-1637:DESCRIPTION:Web-based mail program allows internal network scanning using a modified POP3 port number.:LINK:https://www.cve.org/CVERecord?id=CVE-2010-1637::REFERENCE:CVE-2009-0037:DESCRIPTION:URL-downloading library automatically follows redirects to file:// and scp:// URLs:LINK:https://www.cve.org/CVERecord?id=CVE-2009-0037::"
This issue can make it more difficult to understand and maintain the product. It can make it more difficult and time-consuming to detect and/or fix vulnerabilities.,::NATURE:ChildOf:CWE ID:1059:VIEW ID:1000:ORDINAL:Primary::,N/A,N/A
"When technical documentation is limited or lacking, products are more difficult to maintain. This indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. When using time-limited or labor-limited third-party/in-house security consulting services (such as threat modeling, vulnerability discovery, or pentesting), insufficient documentation can force those consultants to invest unnecessary time in learning how the product is organized, instead of focusing their expertise on finding the flaws or suggesting effective mitigations. With respect to hardware design, the lack of a formal, final manufacturer reference can make it difficult or impossible to evaluate the final product, including post-manufacture verification. One cannot ensure that design functionality or operation is within acceptable tolerances, conforms to specifications, and is free from unexpected behavior. Hardware-related documentation may include engineering artifacts such as hardware description language (HDLs), netlists, Gerber files, Bills of Materials, EDA (Electronic Design Automation) tool files, etc.",::NATURE:ChildOf:CWE ID:710:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Documentation Architecture and Design:DESCRIPTION:Ensure that design documentation is detailed enough to allow for post-manufacturing verification.::,"::REFERENCE:CVE-2022-3203:DESCRIPTION:A wireless access point manual specifies that the only method of configuration is via web interface (CWE-1059), but there is an undisclosed telnet server that was activated by default (CWE-912).:LINK:https://www.cve.org/CVERecord?id=CVE-2022-3203::"
"A System-On-a-Chip (SoC) has a lot of functionality, but it may have a limited number of pins or pads. A pin can only perform one function at a time. However, it can be configured to perform multiple different functions. This technique is called pin multiplexing. Similarly, several resources on the chip may be shared to multiplex and support different features or functions. When such resources are shared between trusted and untrusted agents, untrusted agents may be able to access the assets intended to be accessed only by the trusted agents.",::NATURE:ChildOf:CWE ID:653:VIEW ID:1000:ORDINAL:Primary::NATURE:ChildOf:CWE ID:668:VIEW ID:1000::NATURE:PeerOf:CWE ID:1331:VIEW ID:1000::,"::PHASE:Architecture and Design:STRATEGY:Separation of Privilege:DESCRIPTION:When sharing resources, avoid mixing agents of varying trust levels. Untrusted agents should not share resources with trusted agents.::","::REFERENCE:CVE-2020-8698:DESCRIPTION:Processor has improper isolation of shared resources allowing for information disclosure.:LINK:https://www.cve.org/CVERecord?id=CVE-2020-8698::REFERENCE:CVE-2019-6260:DESCRIPTION:Baseboard Management Controller (BMC) device implements Advanced High-performance Bus (AHB) bridges that do not require authentication for arbitrary read and write access to the BMC's physical address space from the host, and possibly the network [REF-1138].:LINK:https://www.cve.org/CVERecord?id=CVE-2019-6260::"
"DMA is included in a number of devices because it allows data transfer between the computer and the connected device, using direct hardware access to read or write directly to main memory without any OS interaction. An attacker could exploit this to access secrets. Several virtualization-based mitigations have been introduced to thwart DMA attacks. These are usually configured/setup during boot time. However, certain IPs that are powered up before boot is complete (known as early boot IPs) may be DMA capable. Such IPs, if not trusted, could launch DMA attacks and gain access to assets that should otherwise be protected.",::NATURE:ChildOf:CWE ID:696:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design:DESCRIPTION:Utilize an IOMMU to orchestrate IO access from the start of the boot process.::,N/A
"A device's internal information may be accessed through a scan chain of interconnected internal registers, usually through a JTAG interface. The JTAG interface provides access to these registers in a serial fashion in the form of a scan chain for the purposes of debugging programs running on a device. Since almost all information contained within a device may be accessed over this interface, device manufacturers typically insert some form of authentication and authorization to prevent unintended use of this sensitive information. This mechanism is implemented in addition to on-chip protections that are already present. If authorization, authentication, or some other form of access control is not implemented or not implemented correctly, a user may be able to bypass on-chip protection mechanisms through the debug interface. Sometimes, designers choose not to expose the debug pins on the motherboard. Instead, they choose to hide these pins in the intermediate layers of the board. This is primarily done to work around the lack of debug authorization inside the chip. In such a scenario (without debug authorization), when the debug interface is exposed, chip internals are accessible to an attacker.",::NATURE:ChildOf:CWE ID:284:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design:STRATEGY:Separation of Privilege:DESCRIPTION:If feasible, the manufacturer should disable the JTAG interface or implement authentication and authorization for the JTAG interface. If authentication logic is added, it should be resistant to timing attacks. Security-sensitive data stored in registers, such as keys, etc. should be cleared when entering debug mode.:EFFECTIVENESS:High::","::REFERENCE:CVE-2019-18827:DESCRIPTION:chain: JTAG interface is not disabled (CWE-1191) during ROM code execution, introducing a race condition (CWE-362) to extract encryption keys:LINK:https://www.cve.org/CVERecord?id=CVE-2019-18827::"
"A System-on-Chip (SoC) comprises several components (IP) with varied trust requirements. It is required that each IP is identified uniquely and should distinguish itself from other entities in the SoC without any ambiguity. The unique secured identity is required for various purposes. Most of the time the identity is used to route a transaction or perform certain actions, including resetting, retrieving a sensitive information, and acting upon or on behalf of something else. There are several variants of this weakness: A missing identifier is when the SoC does not define any mechanism to uniquely identify the IP. An insufficient identifier might provide some defenses - for example, against the most common attacks - but it does not protect against everything that is intended. A misconfigured mechanism occurs when a mechanism is available but not implemented correctly. An ignored identifier occurs when the SoC/IP has not applied any policies or does not act upon the identifier securely.",::NATURE:ChildOf:CWE ID:657:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design:STRATEGY:Separation of Privilege:DESCRIPTION:Every identity generated in the SoC should be unique and immutable in hardware. The actions that an IP is trusted or not trusted should be clearly defined, implemented, configured, and tested. If the definition is implemented via a policy, then the policy should be immutable or protected with clear authentication and authorization.::",N/A
"After initial reset, System-on-Chip (SoC) fabric access controls and other security features need to be programmed by trusted firmware as part of the boot sequence. If untrusted IPs or peripheral microcontrollers are enabled first, then the untrusted component can master transactions on the hardware bus and target memory or other assets to compromise the SoC boot firmware.",::NATURE:ChildOf:CWE ID:696:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design:DESCRIPTION:The boot sequence should enable fabric access controls and memory protections before enabling third-party hardware IPs and peripheral microcontrollers that use untrusted firmware.::,N/A
"Reserved bits are labeled as such so they can be allocated for a later purpose. They are not to do anything in the current design. However, designers might want to use these bits to debug or control/configure a future capability to help minimize time to market (TTM). If the logic being controlled by these bits is still enabled in production, an adversary could use the logic to induce unwanted/unsupported behavior in the hardware.",::NATURE:ChildOf:CWE ID:710:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design Implementation:DESCRIPTION:Include a feature to disable reserved bits.::PHASE:Integration:DESCRIPTION:Any writes to these reserve bits are blocked (e.g., ignored, access-protected, etc.), or an exception can be asserted.::",N/A
"Integrated circuits and hardware engines can expose accesses to assets (device configuration, keys, etc.) to trusted firmware or a software module (commonly set by BIOS/bootloader). This access is typically access-controlled. Upon a power reset, the hardware or system usually starts with default values in registers, and the trusted firmware (Boot firmware) configures the necessary access-control protection. A common weakness that can exist in such protection schemes is that access controls or policies are not granular enough. This condition allows agents beyond trusted agents to access assets and could lead to a loss of functionality or the ability to set up the device securely. This further results in security risks from leaked, sensitive, key material to modification of device configuration.",::NATURE:ChildOf:CWE ID:284:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design Implementation Testing:DESCRIPTION:Access-control-policy protections must be reviewed for design inconsistency and common weaknesses. Access-control-policy definition and programming flow must be tested in pre-silicon, post-silicon testing.:EFFECTIVENESS:High::","::REFERENCE:CVE-2022-24985:DESCRIPTION:A form hosting website only checks the session authentication status for a single form, making it possible to bypass authentication when there are multiple forms:LINK:https://www.cve.org/CVERecord?id=CVE-2022-24985::REFERENCE:CVE-2021-36934:DESCRIPTION:An operating system has an overly permission Access Control List onsome system files, including those related to user passwords:LINK:https://www.cve.org/CVERecord?id=CVE-2021-36934::"
"Integrated circuits and hardware IP software programmable controls and settings are commonly stored in register circuits. These register contents have to be initialized at hardware reset to defined default values that are hard coded in the hardware description language (HDL) code of the hardware unit. Hardware descriptive languages also support definition of parameter variables, which can be defined in code during instantiation of the hardware IP module. Such parameters are generally used to configure a specific instance of a hardware IP in the design. The system security settings of a hardware design can be affected by incorrectly defined default values or IP parameters. The hardware IP would be in an insecure state at power reset, and this can be exposed or exploited by untrusted software running on the system. Both register defaults and parameters are hardcoded values, which cannot be changed using software or firmware patches but must be changed in hardware silicon. Thus, such security issues are considerably more difficult to address later in the lifecycle. Hardware designs can have a large number of such parameters and register defaults settings, and it is important to have design tool support to check these settings in an automated way and be able to identify which settings are security sensitive.",::NATURE:ChildOf:CWE ID:1419:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design:DESCRIPTION:During hardware design, all the system parameters and register defaults must be reviewed to identify security sensitive settings.::PHASE:Implementation:DESCRIPTION:The default values of these security sensitive settings need to be defined as part of the design review phase.::PHASE:Testing:DESCRIPTION:Testing phase should use automated tools to test that values are configured per design specifications.::",N/A
"Integrated circuits and hardware IPs can expose the device configuration controls that need to be programmed after device power reset by a trusted firmware or software module (commonly set by BIOS/bootloader) and then locked from any further modification. In hardware design, this is commonly implemented using a programmable lock bit which enables/disables writing to a protected set of registers or address regions. When the programmable lock bit is set, the relevant address region can be implemented as a hardcoded value in hardware logic that cannot be changed later. A problem can arise wherein the protected region definition is not granular enough. After the programmable lock bit has been set, then this new functionality cannot be implemented without change to the hardware design.",::NATURE:ChildOf:CWE ID:1220:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design:DESCRIPTION:The defining of protected locked registers should be reviewed or tested early in the design phase with software teams to ensure software flows are not blocked by the security locks. As an alternative to using register lock control bits and fixed access control regions, the hardware design could use programmable security access control configuration so that device trusted firmware can configure and change the protected regions based on software usage and security models.::",N/A
"Integrated circuits and hardware IP software programmable controls and settings are commonly stored in register circuits. These register contents have to be initialized at hardware reset to defined default values that are hard coded in the hardware description language (HDL) code of the hardware unit. A common security protection method used to protect register settings from modification by software is to make them write-once. This means the hardware implementation only allows writing to such registers once, and they become read-only after having been written once by software. This is useful to allow initial boot software to configure systems settings to secure values while blocking runtime software from modifying such hardware settings. Implementation issues in hardware design of such controls can expose such registers to a race condition security flaw. For example, consider a hardware design that has two different software/firmware modules executing in parallel. One module is trusted (module A) and another is untrusted (module B). In this design it could be possible for Module B to send write cycles to the write-once register before Module A. Since the field is write-once the programmed value from Module A will be ignored and the pre-empted value programmed by Module B will be used by hardware.",::NATURE:ChildOf:CWE ID:362:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design:DESCRIPTION:During hardware design all register write-once or sticky fields must be evaluated for proper configuration.::PHASE:Testing:DESCRIPTION:The testing phase should use automated tools to test that values are not reprogrammable and that write-once fields lock on writing zeros.::,N/A
"Integrated circuits and hardware IP software programmable controls and settings are commonly stored in register circuits. These register contents have to be initialized at hardware reset to define default values that are hard coded in the hardware description language (HDL) code of the hardware unit. A common security protection method used to protect register settings from modification by software is to make the settings write-once or sticky. This allows writing to such registers only once, whereupon they become read-only. This is useful to allow initial boot software to configure systems settings to secure values while blocking runtime software from modifying such hardware settings. Failure to implement write-once restrictions in hardware design can expose such registers to being re-programmed by software and written multiple times. For example, write-once fields could be implemented to only be write-protected if they have been set to value 1, wherein they would work as write-1-once and not write-once.",::NATURE:ChildOf:CWE ID:284:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design:DESCRIPTION:During hardware design all register write-once or sticky fields must be evaluated for proper configuration.::PHASE:Testing:DESCRIPTION:The testing phase should use automated tools to test that values are not reprogrammable and that write-once fields lock on writing zeros.::,N/A
"In integrated circuits and hardware intellectual property (IP) cores, device configuration controls are commonly programmed after a device power reset by a trusted firmware or software module (e.g., BIOS/bootloader) and then locked from any further modification. This behavior is commonly implemented using a trusted lock bit. When set, the lock bit disables writes to a protected set of registers or address regions. Design or coding errors in the implementation of the lock bit protection feature may allow the lock bit to be modified or cleared by software after it has been set. Attackers might be able to unlock the system and features that the bit is intended to protect.",::NATURE:ChildOf:CWE ID:284:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design Implementation Testing:DESCRIPTION:Security lock bit protections must be reviewed for design inconsistency and common weaknesses. Security lock programming flow and lock properties must be tested in pre-silicon and post-silicon testing.:EFFECTIVENESS:High::,::REFERENCE:CVE-2017-6283:DESCRIPTION:chip reset clears critical read/write lock permissions for RSA function:LINK:https://www.cve.org/CVERecord?id=CVE-2017-6283::
"Devices may allow device configuration controls which need to be programmed after device power reset via a trusted firmware or software module (commonly set by BIOS/bootloader) and then locked from any further modification. This action is commonly implemented using a programmable lock bit, which, when set, disables writes to a protected set of registers or address regions. After a power state transition, the lock bit is set to unlocked. Some common weaknesses that can exist in such a protection scheme are that the lock gets cleared, the values of the protected registers get reset, or the lock become programmable.",::NATURE:ChildOf:CWE ID:667:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design Implementation Testing:DESCRIPTION:Security Lock bit protections should be reviewed for behavior across supported power state transitions. Security lock programming flow and lock properties should be tested in pre-silicon and post-silicon testing including testing across power transitions.:EFFECTIVENESS:High::,N/A
"Integrated circuits and hardware intellectual properties (IPs) might provide device configuration controls that need to be programmed after device power reset by a trusted firmware or software module, commonly set by BIOS/bootloader. After reset, there can be an expectation that the controls cannot be used to perform any further modification. This behavior is commonly implemented using a trusted lock bit, which can be set to disable writes to a protected set of registers or address regions. The lock protection is intended to prevent modification of certain system configuration (e.g., memory/memory protection unit configuration). However, if the lock bit does not effectively write-protect all system registers or controls that could modify the protected system configuration, then an adversary may be able to use software to access the registers/controls and modify the protected hardware configuration.",::NATURE:ChildOf:CWE ID:284:VIEW ID:1000:ORDINAL:Primary::NATURE:ChildOf:CWE ID:667:VIEW ID:1000::,::PHASE:Architecture and Design Implementation Testing:DESCRIPTION:Security lock bit protections must be reviewed for design inconsistency and common weaknesses. Security lock programming flow and lock properties must be tested in pre-silicon and post-silicon testing.::,"::REFERENCE:CVE-2018-9085:DESCRIPTION:Certain servers leave a write protection lock bit unset after boot, potentially allowing modification of parts of flash memory.:LINK:https://www.cve.org/CVERecord?id=CVE-2018-9085::REFERENCE:CVE-2014-8273:DESCRIPTION:Chain: chipset has a race condition (CWE-362) between when an interrupt handler detects an attempt to write-enable the BIOS (in violation of the lock bit), and when the handler resets the write-enable bit back to 0, allowing attackers to issue BIOS writes during the timing window [REF-1237].:LINK:https://www.cve.org/CVERecord?id=CVE-2014-8273::"
"Device configuration controls are commonly programmed after a device power reset by a trusted firmware or software module (e.g., BIOS/bootloader) and then locked from any further modification. This is commonly implemented using a trusted lock bit, which when set, disables writes to a protected set of registers or address regions. The lock protection is intended to prevent modification of certain system configuration (e.g., memory/memory protection unit configuration). If debug features supported by hardware or internal modes/system states are supported in the hardware design, modification of the lock protection may be allowed allowing access and modification of configuration information.",::NATURE:ChildOf:CWE ID:667:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design Implementation Testing:DESCRIPTION:Security Lock bit protections should be reviewed for any bypass/override modes supported. Any supported override modes either should be removed or protected using authenticated debug modes. Security lock programming flow and lock properties should be tested in pre-silicon and post-silicon testing.:EFFECTIVENESS:High::,N/A
"Hardware logic operates on data stored in registers local to the hardware block. Most hardware IPs, including cryptographic accelerators, rely on registers to buffer I/O, store intermediate values, and interface with software. The result of this is that sensitive information, such as passwords or encryption keys, can exist in locations not transparent to the user of the hardware logic. When a different entity obtains access to the IP due to a change in operating mode or conditions, the new entity can extract information belonging to the previous user if no mechanisms are in place to clear register contents. It is important to clear information stored in the hardware if a physical attack on the product is detected, or if the user of the hardware block changes. The process of clearing register contents in a hardware IP is referred to as zeroization in standards for cryptographic hardware modules such as FIPS-140-2 [REF-267].",::NATURE:ChildOf:CWE ID:226:VIEW ID:1000:ORDINAL:Primary::NATURE:ChildOf:CWE ID:226:VIEW ID:1194:ORDINAL:Primary::,"::PHASE:Architecture and Design:DESCRIPTION:Every register potentially containing sensitive information must have a policy specifying how and when information is cleared, in addition to clarifying if it is the responsibility of the hardware logic or IP user to initiate the zeroization procedure at the appropriate time.::",N/A
"Cryptographic protocols and systems depend on cryptographic primitives (and associated algorithms) as their basic building blocks. Some common examples of primitives are digital signatures, one-way hash functions, ciphers, and public key cryptography; however, the notion of primitive can vary depending on point of view. See Terminology Notes for further explanation of some concepts. Cryptographic primitives are defined to accomplish one very specific task in a precisely defined and mathematically reliable fashion. For example, suppose that for a specific cryptographic primitive (such as an encryption routine), the consensus is that the primitive can only be broken after trying out N different inputs (where the larger the value of N, the stronger the cryptography). For an encryption scheme like AES-256, one would expect N to be so large as to be infeasible to execute in a reasonable amount of time. If a vulnerability is ever found that shows that one can break a cryptographic primitive in significantly less than the expected number of attempts, then that primitive is considered weakened (or sometimes in extreme cases, colloquially it is broken). As a result, anything using this cryptographic primitive would now be considered insecure or risky. Thus, even breaking or weakening a seemingly small cryptographic primitive has the potential to render the whole system vulnerable, due to its reliance on the primitive. A historical example can be found in TLS when using DES. One would colloquially call DES the cryptographic primitive for transport encryption in this version of TLS. In the past, DES was considered strong, because no weaknesses were found in it; importantly, DES has a key length of 56 bits. Trying N=2^56 keys was considered impractical for most actors. Unfortunately, attacking a system with 56-bit keys is now practical via brute force, which makes defeating DES encryption practical. It is now practical for an adversary to read any information sent under this version of TLS and use this information to attack the system. As a result, it can be claimed that this use of TLS is weak, and that any system depending on TLS with DES could potentially render the entire system vulnerable to attack. Cryptographic primitives and associated algorithms are only considered safe after extensive research and review from experienced cryptographers from academia, industry, and government entities looking for any possible flaws. Furthermore, cryptographic primitives and associated algorithms are frequently reevaluated for safety when new mathematical and attack techniques are discovered. As a result and over time, even well-known cryptographic primitives can lose their compliance status with the discovery of novel attacks that might either defeat the algorithm or reduce its robustness significantly. If ad-hoc cryptographic primitives are implemented, it is almost certain that the implementation will be vulnerable to attacks that are well understood by cryptographers, resulting in the exposure of sensitive information and other consequences. This weakness is even more difficult to manage for hardware-implemented deployment of cryptographic algorithms. First, because hardware is not patchable as easily as software, any flaw discovered after release and production typically cannot be fixed without a recall of the product. Secondly, the hardware product is often expected to work for years, during which time computation power available to the attacker only increases. Therefore, for hardware implementations of cryptographic primitives, it is absolutely essential that only strong, proven cryptographic primitives are used.",::NATURE:ChildOf:CWE ID:327:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Requirements:DESCRIPTION:Require compliance with the strongest-available recommendations from trusted parties, and require that compliance must be kept up-to-date, since recommendations evolve over time. For example, US government systems require FIPS 140-3 certification, which supersedes FIPS 140-2 [REF-1192] [REF-1226].:EFFECTIVENESS:High::PHASE:Architecture and Design:DESCRIPTION:Ensure that the architecture/design uses the strongest-available primitives and algorithms from trusted parties. For example, US government systems require FIPS 140-3 certification, which supersedes FIPS 140-2 [REF-1192] [REF-1226].:EFFECTIVENESS:High::PHASE:Architecture and Design:DESCRIPTION:Do not develop custom or private cryptographic algorithms. They will likely be exposed to attacks that are well-understood by cryptographers. As with all cryptographic mechanisms, the source code should be available for analysis. If the algorithm may be compromised when attackers find out how it works, then it is especially weak.:EFFECTIVENESS:Discouraged Common Practice::PHASE:Architecture and Design:DESCRIPTION:Try not to use cryptographic algorithms in novel ways or with new modes of operation even when you know it is secure. For example, using SHA-2 chaining to create a 1-time pad for encryption might sound like a good idea, but one should not do this.:EFFECTIVENESS:Discouraged Common Practice::PHASE:Architecture and Design:DESCRIPTION:Ensure that the design can replace one cryptographic primitive or algorithm with another in the next generation (cryptographic agility). Where possible, use wrappers to make the interfaces uniform. This will make it easier to upgrade to stronger algorithms. This is especially important for hardware, which can be more difficult to upgrade quickly than software; design the hardware at a replaceable block level.:EFFECTIVENESS:Defense in Depth::PHASE:Architecture and Design:DESCRIPTION:Do not use outdated or non-compliant cryptography algorithms. Some older algorithms, once thought to require a billion years of computing time, can now be broken in days or hours. This includes MD4, MD5, SHA1, DES, and other algorithms that were once regarded as strong [REF-267].:EFFECTIVENESS:Discouraged Common Practice::PHASE:Architecture and Design Implementation:DESCRIPTION:Do not use a linear-feedback shift register (LFSR) or other legacy methods as a substitute for an accepted and standard Random Number Generator.:EFFECTIVENESS:Discouraged Common Practice::PHASE:Architecture and Design Implementation:DESCRIPTION:Do not use a checksum as a substitute for a cryptographically generated hash.:EFFECTIVENESS:Discouraged Common Practice::PHASE:Architecture and Design:STRATEGY:Libraries or Frameworks:DESCRIPTION:Use a vetted cryptographic library or framework. Industry-standard implementations will save development time and are more likely to avoid errors that can occur during implementation of cryptographic algorithms. However, the library/framework could be used incorrectly during implementation.:EFFECTIVENESS:High::PHASE:Architecture and Design Implementation:DESCRIPTION:When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for the prevention of common attacks.:EFFECTIVENESS:Moderate::PHASE:Architecture and Design Implementation:DESCRIPTION:Do not store keys in areas accessible to untrusted agents. Carefully manage and protect the cryptographic keys (see CWE-320). If the keys can be guessed or stolen, then the strength of the cryptography algorithm is irrelevant.:EFFECTIVENESS:Moderate::","::REFERENCE:CVE-2020-4778:DESCRIPTION:software uses MD5, which is less safe than the default SHA-256 used by related products:LINK:https://www.cve.org/CVERecord?id=CVE-2020-4778::REFERENCE:CVE-2005-2946:DESCRIPTION:Default configuration of product uses MD5 instead of stronger algorithms that are available, simplifying forgery of certificates.:LINK:https://www.cve.org/CVERecord?id=CVE-2005-2946::REFERENCE:CVE-2019-3907:DESCRIPTION:identity card uses MD5 hash of a salt and password:LINK:https://www.cve.org/CVERecord?id=CVE-2019-3907::REFERENCE:CVE-2021-34687:DESCRIPTION:personal key is transmitted over the network using a substitution cipher:LINK:https://www.cve.org/CVERecord?id=CVE-2021-34687::REFERENCE:CVE-2020-14254:DESCRIPTION:product does not disable TLS-RSA cipher suites, allowing decryption of traffic if TLS 2.0 and secure ciphers are not enabled.:LINK:https://www.cve.org/CVERecord?id=CVE-2020-14254::REFERENCE:CVE-2019-1543:DESCRIPTION:SSL/TLS library generates 16-byte nonces but reduces them to 12 byte nonces for the ChaCha20-Poly1305 cipher, converting them in a way that violates the cipher's requirements for unique nonces.:LINK:https://www.cve.org/CVERecord?id=CVE-2019-1543::REFERENCE:CVE-2017-9267:DESCRIPTION:LDAP interface allows use of weak ciphers:LINK:https://www.cve.org/CVERecord?id=CVE-2017-9267::REFERENCE:CVE-2017-7971:DESCRIPTION:SCADA product allows use of outdated cipher suites:LINK:https://www.cve.org/CVERecord?id=CVE-2017-7971::REFERENCE:CVE-2020-6616:DESCRIPTION:Chip implementing Bluetooth uses a low-entropy PRNG instead of a hardware RNG, allowing spoofing.:LINK:https://www.cve.org/CVERecord?id=CVE-2020-6616::REFERENCE:CVE-2019-1715:DESCRIPTION:security product has insufficient entropy in the DRBG, allowing collisions and private key discovery:LINK:https://www.cve.org/CVERecord?id=CVE-2019-1715::REFERENCE:CVE-2014-4192:DESCRIPTION:Dual_EC_DRBG implementation in RSA toolkit does not correctly handle certain byte requests, simplifying plaintext recovery:LINK:https://www.cve.org/CVERecord?id=CVE-2014-4192::REFERENCE:CVE-2007-6755:DESCRIPTION:Recommendation for Dual_EC_DRBG algorithm contains point Q constants that could simplify decryption:LINK:https://www.cve.org/CVERecord?id=CVE-2007-6755::"
"Pseudo-random number generator algorithms are predictable because their registers have a finite number of possible states, which eventually lead to repeating patterns. As a result, pseudo-random number generators (PRNGs) can compromise their randomness or expose their internal state to various attacks, such as reverse engineering or tampering. It is highly recommended to use hardware-based true random number generators (TRNGs) to ensure the security of encryption schemes. TRNGs generate unpredictable, unbiased, and independent random numbers because they employ physical phenomena, e.g., electrical noise, as sources to generate random numbers.",::NATURE:ChildOf:CWE ID:330:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design:DESCRIPTION:A true random number generator should be specified for cryptographic algorithms.::PHASE:Implementation:DESCRIPTION:A true random number generator should be implemented for cryptographic algorithms.::,::REFERENCE:CVE-2021-3692:DESCRIPTION:PHP framework uses mt_rand() function (Marsenne Twister) when generating tokens:LINK:https://www.cve.org/CVERecord?id=CVE-2021-3692::
"A common design practice is to use undocumented bits on a device that can be used to disable certain functional security features. These bits are commonly referred to as chicken bits. They can facilitate quick identification and isolation of faulty components, features that negatively affect performance, or features that do not provide the required controllability for debug and test. Another way to achieve this is through implementation of undocumented features. An attacker might exploit these interfaces for unauthorized access.",::NATURE:ChildOf:CWE ID:912:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design Implementation:DESCRIPTION:The implementation of chicken bits in a released product is highly discouraged. If implemented at all, ensure that they are disabled in production devices. All interfaces to a device should be documented.:EFFECTIVENESS:High::",N/A
"Several security-sensitive values are programmed into fuses to be used during early-boot flows or later at runtime. Examples of these security-sensitive values include root keys, encryption keys, manufacturing-specific information, chip-manufacturer-specific information, and original-equipment-manufacturer (OEM) data. After the chip is powered on, these values are sensed from fuses and stored in temporary locations such as registers and local memories. These locations are typically access-control protected from untrusted agents capable of accessing them. Even to trusted agents, only read-access is provided. However, these locations are not blocked during debug operations, allowing a user to access this sensitive information.",::NATURE:ChildOf:CWE ID:1263:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design Implementation:DESCRIPTION:Disable access to security-sensitive information stored in fuses directly and also reflected from temporary storage locations when in debug mode.::,N/A
"Debug authorization can have multiple levels of access, defined such that different system internal assets are accessible based on the current authorized debug level. Other than debugger authentication (e.g., using passwords or challenges), the authorization can also be based on the system state or boot stage. For example, full system debug access might only be allowed early in boot after a system reset to ensure that previous session data is not accessible to the authenticated debugger. If this protection mechanism does not ensure that internal assets have the correct debug access level during each boot stage or change in system state, an attacker could obtain sensitive information from the internal asset using a debugger.",::NATURE:ChildOf:CWE ID:863:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design Implementation:DESCRIPTION:For security-sensitive assets accessible over debug/test interfaces, only allow trusted agents.:EFFECTIVENESS:High::PHASE:Architecture and Design:DESCRIPTION:Apply blinding [REF-1219] or masking techniques in strategic areas.:EFFECTIVENESS:Limited::PHASE:Implementation:DESCRIPTION:Add shielding or tamper-resistant protections to the device, which increases the difficulty and cost for accessing debug/test interfaces.:EFFECTIVENESS:Limited::","::REFERENCE:CVE-2019-18827:DESCRIPTION:After ROM code execution, JTAG access is disabled. But before the ROM code is executed, JTAG access is possible, allowing a user full system access. This allows a user to modify the boot flow and successfully bypass the secure-boot process.:LINK:https://www.cve.org/CVERecord?id=CVE-2019-18827::"
"The functionality and security of the system heavily depend on the implementation of FSMs. FSMs can be used to indicate the current security state of the system. Lots of secure data operations and data transfers rely on the state reported by the FSM. Faulty FSM designs that do not account for all states, either through undefined states (left as don't cares) or through incorrect implementation, might lead an attacker to drive the system into an unstable state from which the system cannot recover without a reset, thus causing a DoS. Depending on what the FSM is used for, an attacker might also gain additional privileges to launch further attacks and compromise the security guarantees.",::NATURE:ChildOf:CWE ID:684:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design Implementation:DESCRIPTION:Define all possible states and handle all unused states through default statements. Ensure that system defaults to a secure state.:EFFECTIVENESS:High::,N/A
"Non-volatile memories such as NAND Flash, EEPROM, etc. have individually erasable segments, each of which can be put through a limited number of program/erase or write cycles. For example, the device can only endure a limited number of writes, after which the device becomes unreliable. In order to wear out the cells in a uniform manner, non-volatile memory and storage products based on the above-mentioned technologies implement a technique called wear leveling. Once a set threshold is reached, wear leveling maps writes of a logical block to a different physical block. This prevents a single physical block from prematurely failing due to a high concentration of writes. If wear leveling is improperly implemented, attackers may be able to programmatically cause the storage to become unreliable within a much shorter time than would normally be expected.",::NATURE:ChildOf:CWE ID:400:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design Implementation Testing:DESCRIPTION:Include secure wear leveling algorithms and ensure they may not be bypassed.:EFFECTIVENESS:High::,N/A
"A device might support features such as secure boot which are supplemented with hardware and firmware support. This involves establishing a chain of trust, starting with an immutable root of trust by checking the signature of the next stage (culminating with the OS and runtime software) against a golden value before transferring control. The intermediate stages typically set up the system in a secure state by configuring several access control settings. Similarly, security logic for exercising a debug or testing interface may be implemented in hardware, firmware, or both. A device needs to guard against fault attacks such as voltage glitches and clock glitches that an attacker may employ in an attempt to compromise the system.",::NATURE:ChildOf:CWE ID:1384:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design Implementation:DESCRIPTION:At the circuit-level, using Tunable Replica Circuits (TRCs) or special flip-flops such as Razor flip-flops helps mitigate glitch attacks. Working at the SoC or platform base, level sensors may be implemented to detect glitches. Implementing redundancy in security-sensitive code (e.g., where checks are performed)also can help with mitigation of glitch attacks.::",::REFERENCE:CVE-2019-17391:DESCRIPTION:Lack of anti-glitch protections allows an attacker to launch a physical attack to bypass the secure boot and read protected eFuses.:LINK:https://www.cve.org/CVERecord?id=CVE-2019-17391::REFERENCE:CVE-2021-33478:DESCRIPTION:IP communication firmware allows access to a boot shell via certain impulses:LINK:https://www.cve.org/CVERecord?id=CVE-2021-33478::
"A semiconductor device can fail for various reasons. While some are manufacturing and packaging defects, the rest are due to prolonged use or usage under extreme conditions. Some mechanisms that lead to semiconductor defects include encapsulation failure, die-attach failure, wire-bond failure, bulk-silicon defects, oxide-layer faults, aluminum-metal faults (including electromigration, corrosion of aluminum, etc.), and thermal/electrical stress. These defects manifest as faults on chip-internal signals or registers, have the effect of inputs, outputs, or intermediate signals being always 0 or always 1, and do not switch as expected. If such faults occur in security-sensitive hardware modules, the security objectives of the hardware module may be compromised.",::NATURE:ChildOf:CWE ID:693:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Testing:DESCRIPTION:While semiconductor-manufacturing companies implement several mechanisms to continuously improve the semiconductor manufacturing process to ensure reduction of defects, some defects can only be fixed after manufacturing. Post-manufacturing testing of silicon die is critical. Fault models such as stuck-at-0 or stuck-at-1 must be used to develop post-manufacturing test cases and achieve good coverage. Once the silicon packaging is done, extensive post-silicon testing must be performed to ensure that hardware logic implementing security functionalities is defect-free.::PHASE:Operation:DESCRIPTION:Operating the hardware outside device specification, such as at extremely high temperatures, voltage, etc., accelerates semiconductor degradation and results in defects. When these defects manifest as faults in security-critical, hardware modules, it results in compromise of security guarantees. Thus, operating the device within the specification is important.::",N/A
"In highly distributed environments, or on systems with distinct physical components that operate independently, there is often a need for each component to store and update its own local copy of key data such as state or cache, so that all components have the same view of the overall system and operate in a coordinated fashion. For example, users of a social media service or a massively multiplayer online game might be using their own personal computers while also interacting with different physical hosts in a globally distributed service, but all participants must be able to have the same view of the world. Alternately, a processor's Memory Management Unit (MMU) might have shadow MMUs to distribute its workload, and all shadow MMUs are expected to have the same accessible ranges of memory. In such environments, it becomes critical for the product to ensure that this shared state is consistently modified across all distributed systems. If state is not consistently maintained across all systems, then critical transactions might take place out of order, or some users might not get the same data as other users. When this inconsistency affects correctness of operations, it can introduce vulnerabilities in mechanisms that depend on consistent state.",::NATURE:ChildOf:CWE ID:664:VIEW ID:1000:ORDINAL:Primary::,N/A,N/A
"Having mirrored regions with different values might result in the exposure of sensitive information or possibly system compromise. In the interest of increased performance, one might need to duplicate a resource. A cache memory is a common example of this concept, which keeps a local copy of a data element in the high speed cache memory. Unfortunately, this speed improvement comes with a downside, since the product needs to ensure that the local copy always mirrors the original copy truthfully. If they get out of sync, the computational result is no longer true. During hardware design, memory is not the only item which gets mirrored. There are many other entities that get mirrored, as well: registers, memory regions, and, in some cases, even whole computational units. For example, within a multi-core processor, if all memory accesses for each and every core goes through a single Memory-Management Unit (MMU) then the MMU will become a performance bottleneck. In such cases, duplicating local MMUs that will serve only a subset of the cores rather than all of them may resolve the performance issue. These local copies are also called shadow copies or mirrored copies. If the original resource never changed, local duplicate copies getting out of sync would never be an issue. However, the values of the original copy will sometimes change. When the original copy changes, the mirrored copies must also change, and change fast. This situation of shadow-copy-possibly-out-of-sync-with-original-copy might occur as a result of multiple scenarios, including the following: After the values in the original copy change, due to some reason the original copy does not send the update request to its shadow copies. After the values in the original copy change, the original copy dutifully sends the update request to its shadow copies, but due to some reason the shadow copy does not execute this update request. After the values in the original copy change, the original copy sends the update request to its shadow copies, and the shadow copy executes this update request faithfully. However, during the small time period when the original copy has new values and the shadow copy is still holding the old values, an attacker can exploit the old values. Then it becomes a race condition between the attacker and the update process of who can reach the target, shadow copy first, and, if the attacker reaches first, the attacker wins. The attacker might send a spoofed update request to the target shadow copy, pretending that this update request is coming from the original copy. This spoofed request might cause the targeted shadow copy to update its values to some attacker-friendly values, while the original copies remain unchanged by the attacker. Suppose a situation where the original copy has a system of reverting back to its original value if it does not hear back from all the shadow copies that such copies have successfully completed the update request. In such a case, an attack might occur as follows: (1) the original copy might send an update request; (2) the shadow copy updates it; (3) the shadow copy sends back the successful completion message; (4) through a separate issue, the attacker is able to intercept the shadow copy's completion message. In this case, the original copy thinks that the update did not succeed, hence it reverts to its original value. Now there is a situation where the original copy has the old value, and the shadow copy has the new value.",::NATURE:ChildOf:CWE ID:1250:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design:DESCRIPTION:Whenever there are multiple, physically different copies of the same value that might change and the process to update them is not instantaneous and atomic, it is impossible to assert that the original and shadow copies will always be in sync - there will always be a time period when they are out of sync. To mitigate the consequential risk, the recommendations essentially are: Make this out-of-sync time period as small as possible, and Make the update process as robust as possible.:EFFECTIVENESS:Moderate::",N/A
"CPUs provide a special bit that supports exclusivity of write and execute operations. This bit is used to segregate areas of memory to either mark them as code (instructions, which can be executed) or data (which should not be executed). In this way, if a user can write to a region of memory, the user cannot execute from that region and vice versa. This exclusivity provided by special hardware bit is leveraged by the operating system to protect executable space. While this bit is available in most modern processors by default, in some CPUs the exclusivity is implemented via a memory-protection unit (MPU) and memory-management unit (MMU) in which memory regions can be carved out with exact read, write, and execute permissions. However, if the CPU does not have an MMU/MPU, then there is no write exclusivity. Without configuring exclusivity of operations via segregated areas of memory, an attacker may be able to inject malicious code onto memory and later execute it.",::NATURE:ChildOf:CWE ID:284:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design:DESCRIPTION:Implement a dedicated bit that can be leveraged by the Operating System to mark data areas as non-executable. If such a bit is not available in the CPU, implement MMU/MPU (memory management unit / memory protection unit).::PHASE:Integration:DESCRIPTION:If MMU/MPU are not available, then the firewalls need to be implemented in the SoC interconnect to mimic the write-exclusivity operation.::",N/A
"Fuses are often used to store secret data, including security configuration data. When not blown, a fuse is considered to store a logic 0, and, when blown, it indicates a logic 1. Fuses are generally considered to be one-directional, i.e., once blown to logic 1, it cannot be reset to logic 0. However, if the logic used to determine system-security state (by leveraging the values sensed from the fuses) uses negative logic, an attacker might blow the fuse and drive the system to an insecure state.",::NATURE:ChildOf:CWE ID:693:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design:DESCRIPTION:Logic should be designed in a way that blown fuses do not put the product into an insecure state that can be leveraged by an attacker.::,N/A
"Comparison logic is used to compare a variety of objects including passwords, Message Authentication Codes (MACs), and responses to verification challenges. When comparison logic is implemented at a finer granularity (e.g., byte-by-byte comparison) and breaks in the case of a comparison failure, an attacker can exploit this implementation to identify when exactly the failure occurred. With multiple attempts, the attacker may be able to guesses the correct password/response to challenge and elevate their privileges.",::NATURE:ChildOf:CWE ID:208:VIEW ID:1000:ORDINAL:Primary::NATURE:ChildOf:CWE ID:697:VIEW ID:1000::,::PHASE:Implementation:DESCRIPTION:The hardware designer should ensure that comparison logic is implemented so as to compare in one operation instead in smaller chunks.::,"::REFERENCE:CVE-2019-10482:DESCRIPTION:Smartphone OS uses comparison functions that are not in constant time, allowing side channels:LINK:https://www.cve.org/CVERecord?id=CVE-2019-10482::REFERENCE:CVE-2019-10071:DESCRIPTION:Java-oriented framework compares HMAC signatures using String.equals() instead of a constant-time algorithm, causing timing discrepancies:LINK:https://www.cve.org/CVERecord?id=CVE-2019-10071::REFERENCE:CVE-2014-0984:DESCRIPTION:Password-checking function in router terminates validation of a password entry when it encounters the first incorrect character, which allows remote attackers to obtain passwords via a brute-force attack that relies on timing differences in responses to incorrect password guesses, aka a timing side-channel attack.:LINK:https://www.cve.org/CVERecord?id=CVE-2014-0984::"
"The power consumed by a device may be instrumented and monitored in real time. If the algorithm for evaluating security tokens is not sufficiently robust, the power consumption may vary by token entry comparison against the reference value. Further, if retries are unlimited, the power difference between a good entry and a bad entry may be observed and used to determine whether each entry itself is correct thereby allowing unauthorized parties to calculate the reference value.",::NATURE:ChildOf:CWE ID:1300:VIEW ID:1000:ORDINAL:Primary::NATURE:PeerOf:CWE ID:1259:VIEW ID:1194:ORDINAL:Primary::,"::PHASE:Architecture and Design:DESCRIPTION:The design phase must consider each check of a security token against a standard and the amount of power consumed during the check of a good token versus a bad token. The alternative is an all at once check where a retry counter is incremented PRIOR to the check.::PHASE:Architecture and Design:DESCRIPTION:Another potential mitigation is to parallelize shifting of secret data (see example 2 below). Note that the wider the bus the more effective the result.::PHASE:Architecture and Design:DESCRIPTION:An additional potential mitigation is to add random data to each crypto operation then subtract it out afterwards. This is highly effective but costly in performance, area, and power consumption. It also requires a random number generator.::PHASE:Implementation:DESCRIPTION:If the architecture is unable to prevent the attack, using filtering components may reduce the ability to implement an attack, however, consideration must be given to the physical removal of the filter elements.::PHASE:Integration:DESCRIPTION:During integration, avoid use of a single secret for an extended period (e.g. frequent key updates). This limits the amount of data compromised but at the cost of complexity of use.::",::REFERENCE:CVE-2020-12788:DESCRIPTION:CMAC verification vulnerable to timing and power attacks.:LINK:https://www.cve.org/CVERecord?id=CVE-2020-12788::
"It is frequently assumed that physical attacks such as fault injection and side-channel analysis require an attacker to have physical access to the target device. This assumption may be false if the device has improperly secured power management features, or similar features. For mobile devices, minimizing power consumption is critical, but these devices run a wide variety of applications with different performance requirements. Software-controllable mechanisms to dynamically scale device voltage and frequency and monitor power consumption are common features in today's chipsets, but they also enable attackers to mount fault injection and side-channel attacks without having physical access to the device. Fault injection attacks involve strategic manipulation of bits in a device to achieve a desired effect such as skipping an authentication step, elevating privileges, or altering the output of a cryptographic operation. Manipulation of the device clock and voltage supply is a well-known technique to inject faults and is cheap to implement with physical device access. Poorly protected power management features allow these attacks to be performed from software. Other features, such as the ability to write repeatedly to DRAM at a rapid rate from unprivileged software, can result in bit flips in other memory locations (Rowhammer, [REF-1083]). Side channel analysis requires gathering measurement traces of physical quantities such as power consumption. Modern processors often include power metering capabilities in the hardware itself (e.g., Intel RAPL) which if not adequately protected enable attackers to gather measurements necessary for performing side-channel attacks from software.",::NATURE:ChildOf:CWE ID:285:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design Implementation:DESCRIPTION:Ensure proper access control mechanisms protect software-controllable features altering physical operating conditions such as clock frequency and voltage.::,"::REFERENCE:CVE-2019-11157:DESCRIPTION:Plundervolt: Improper conditions check in voltage settings for some Intel(R) Processors may allow a privileged user to potentially enable escalation of privilege and/or information disclosure via local access [REF-1081].:LINK:https://www.cve.org/CVERecord?id=CVE-2019-11157::REFERENCE:CVE-2020-8694:DESCRIPTION:PLATYPUS Attack: Insufficient access control in the Linux kernel driver for some Intel processors allows information disclosure.:LINK:https://www.cve.org/CVERecord?id=CVE-2020-8694::REFERENCE:CVE-2020-8695:DESCRIPTION:Observable discrepancy in the RAPL interface for some Intel processors allows information disclosure.:LINK:https://www.cve.org/CVERecord?id=CVE-2020-8695::REFERENCE:CVE-2020-12912:DESCRIPTION:AMD extension to a Linux service does not require privileged access to the RAPL interface, allowing side-channel attacks.:LINK:https://www.cve.org/CVERecord?id=CVE-2020-12912::REFERENCE:CVE-2015-0565:DESCRIPTION:NaCl in 2015 allowed the CLFLUSH instruction, making Rowhammer attacks possible.:LINK:https://www.cve.org/CVERecord?id=CVE-2015-0565::"
"Hardware product designs often need to implement memory protection features that enable privileged software to define isolated memory regions and access control (read/write) policies. Isolated memory regions can be defined on different memory spaces in a design (e.g. system physical address, virtual address, memory mapped IO). Each memory cell should be mapped and assigned a system address that the core software can use to read/write to that memory. It is possible to map the same memory cell to multiple system addresses such that read/write to any of the aliased system addresses would be decoded to the same memory cell. This is commonly done in hardware designs for redundancy and simplifying address decoding logic. If one of the memory regions is corrupted or faulty, then that hardware can switch to using the data in the mirrored memory region. Memory aliases can also be created in the system address map if the address decoder unit ignores higher order address bits when mapping a smaller address region into the full system address. A common security weakness that can exist in such memory mapping is that aliased memory regions could have different read/write access protections enforced by the hardware such that an untrusted agent is blocked from accessing a memory address but is not blocked from accessing the corresponding aliased memory address. Such inconsistency can then be used to bypass the access protection of the primary memory block and read or modify the protected memory. An untrusted agent could also possibly create memory aliases in the system address map for malicious purposes if it is able to change the mapping of an address region or modify memory region sizes.",::NATURE:ChildOf:CWE ID:284:VIEW ID:1000:ORDINAL:Primary::NATURE:CanPrecede:CWE ID:119:VIEW ID:1000::,"::PHASE:Architecture and Design Implementation:DESCRIPTION:The checks should be applied for consistency access rights between primary memory regions and any mirrored or aliased memory regions. If different memory protection units (MPU) are protecting the aliased regions, their protected range definitions and policies should be synchronized.::PHASE:Architecture and Design Implementation:DESCRIPTION:The controls that allow enabling memory aliases or changing the size of mapped memory regions should only be programmable by trusted software components.::",N/A
"Security sensitive values, keys, intermediate steps of cryptographic operations, etc. are stored in temporary registers in the hardware. If these values are not cleared when debug mode is entered they may be accessed by a debugger allowing sensitive information to be accessible by untrusted parties.",::NATURE:ChildOf:CWE ID:212:VIEW ID:1000:ORDINAL:Primary::NATURE:ChildOf:CWE ID:200:VIEW ID:1000::,"::PHASE:Architecture and Design:DESCRIPTION:Whenever debug mode is enabled, all registers containing sensitive assets must be cleared.::",::REFERENCE:CVE-2021-33080:DESCRIPTION:Uncleared debug information in memory accelerator for SSD product exposes sensitive system information:LINK:https://www.cve.org/CVERecord?id=CVE-2021-33080::REFERENCE:CVE-2022-31162:DESCRIPTION:Rust library leaks Oauth client details in application debug logs:LINK:https://www.cve.org/CVERecord?id=CVE-2022-31162::
"Systems-On-A-Chip (Integrated circuits and hardware engines) implement Security Tokens to differentiate and identify which actions originated from which agent. These actions may be one of the directives: 'read', 'write', 'program', 'reset', 'fetch', 'compute', etc. Security Tokens are assigned to every agent in the System that is capable of generating an action or receiving an action from another agent. Multiple Security Tokens may be assigned to an agent and may be unique based on the agent's trust level or allowed privileges. Since the Security Tokens are integral for the maintenance of security in an SoC, they need to be protected properly. A common weakness afflicting Security Tokens is improperly restricting the assignment to trusted components. Consequently, an improperly protected Security Token may be able to be programmed by a malicious agent (i.e., the Security Token is mutable) to spoof the action as if it originated from a trusted agent.",::NATURE:ChildOf:CWE ID:284:VIEW ID:1000:ORDINAL:Primary::NATURE:ChildOf:CWE ID:1294:VIEW ID:1194:ORDINAL:Primary::,::PHASE:Architecture and Design Implementation:DESCRIPTION:Security Token assignment review checks for design inconsistency and common weaknesses. Security-Token definition and programming flow is tested in both pre-silicon and post-silicon testing.::,N/A
"Isolated memory regions and access control (read/write) policies are used by hardware to protect privileged software. Software components are often allowed to change or remap memory region definitions in order to enable flexible and dynamically changeable memory management by system software. If a software component running at lower privilege can program a memory address region to overlap with other memory regions used by software running at higher privilege, privilege escalation may be available to attackers. The memory protection unit (MPU) logic can incorrectly handle such an address overlap and allow the lower-privilege software to read or write into the protected memory region, resulting in privilege escalation attack. An address overlap weakness can also be used to launch a denial of service attack on the higher-privilege software memory regions.",::NATURE:ChildOf:CWE ID:284:VIEW ID:1000:ORDINAL:Primary::NATURE:CanPrecede:CWE ID:119:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design:DESCRIPTION:Ensure that memory regions are isolated as intended and that access control (read/write) policies are used by hardware to protect privileged software.::PHASE:Implementation:DESCRIPTION:For all of the programmable memory protection regions, the memory protection unit (MPU) design can define a priority scheme. For example: if three memory regions can be programmed (Region_0, Region_1, and Region_2), the design can enforce a priority scheme, such that, if a system address is within multiple regions, then the region with the lowest ID takes priority and the access-control policy of that region will be applied. In some MPU designs, the priority scheme can also be programmed by trusted software. Hardware logic or trusted firmware can also check for region definitions and block programming of memory regions with overlapping addresses. The memory-access-control-check filter can also be designed to apply a policy filter to all of the overlapping ranges, i.e., if an address is within Region_0 and Region_1, then access to this address is only granted if both Region_0 and Region_1 policies allow the access.:EFFECTIVENESS:High::",::REFERENCE:CVE-2008-7096:DESCRIPTION:virtualization product allows compromise of hardware product by accessing certain remapping registers.:LINK:https://www.cve.org/CVERecord?id=CVE-2008-7096::REFERENCE:[REF-1100]:DESCRIPTION:processor design flaw allows ring 0 code to access more privileged rings by causing a register window to overlap a range of protected system RAM [REF-1100]:LINK:https://github.com/xoreaxeaxeax/sinkhole/blob/master/us-15-Domas-TheMemorySinkhole-wp.pdf::
"Technology trends such as CMOS-transistor down-sizing, use of new materials, and system-on-chip architectures continue to increase the sensitivity of systems to soft errors. These errors are random, and their causes might be internal (e.g., interconnect coupling) or external (e.g., cosmic radiation). These soft errors are not permanent in nature and cause temporary bit flips known as single-event upsets (SEUs). SEUs are induced errors in circuits caused when charged particles lose energy by ionizing the medium through which they pass, leaving behind a wake of electron-hole pairs that cause temporary failures. If these failures occur in security-sensitive modules in a chip, it might compromise the security guarantees of the chip. For instance, these temporary failures could be bit flips that change the privilege of a regular user to root.",::NATURE:ChildOf:CWE ID:1384:VIEW ID:1000:ORDINAL:Primary::NATURE:PeerOf:CWE ID:1254:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design:DESCRIPTION:Implement triple-modular redundancy around security-sensitive modules.::PHASE:Architecture and Design:DESCRIPTION:SEUs mostly affect SRAMs. For SRAMs storing security-critical data, implement Error-Correcting-Codes (ECC) and Address Interleaving.::",N/A
"Software commonly accesses peripherals in a System-on-Chip (SoC) or other device through a memory-mapped register interface. Malicious software could tamper with any security-critical hardware data that is accessible directly or indirectly through the register interface, which could lead to a loss of confidentiality and integrity.",::NATURE:ChildOf:CWE ID:284:VIEW ID:1000:ORDINAL:Primary::,::PHASE:Architecture and Design:DESCRIPTION:Design proper policies for hardware register access from software.::PHASE:Implementation:DESCRIPTION:Ensure that access control policies for register access are implemented in accordance with the specified design.::,"::REFERENCE:CVE-2014-2915:DESCRIPTION:virtualization product does not restrict access to debug and other processor registers in the hardware, allowing a crash of the host or guest OS:LINK:https://www.cve.org/CVERecord?id=CVE-2014-2915::REFERENCE:CVE-2021-3011:DESCRIPTION:virtual interrupt controller in a virtualization product allows crash of host by writing a certain invalid value to a register, which triggers a fatal error instead of returning an error code:LINK:https://www.cve.org/CVERecord?id=CVE-2021-3011::REFERENCE:CVE-2020-12446:DESCRIPTION:Driver exposes access to Model Specific Register (MSR) registers, allowing admin privileges.:LINK:https://www.cve.org/CVERecord?id=CVE-2020-12446::REFERENCE:CVE-2015-2150:DESCRIPTION:Virtualization product does not restrict access to PCI command registers, allowing host crash from the guest.:LINK:https://www.cve.org/CVERecord?id=CVE-2015-2150::"
Sections of a product intended to have restricted access may be inadvertently or intentionally rendered accessible when the implemented physical protections are insufficient. The specific requirements around how robust the design of the physical protection mechanism needs to be depends on the type of product being protected. Selecting the correct physical protection mechanism and properly enforcing it through implementation and manufacturing are critical to the overall physical security of the product.,::NATURE:ChildOf:CWE ID:284:VIEW ID:1000:ORDINAL:Primary::NATURE:PeerOf:CWE ID:1191:VIEW ID:1000::,::PHASE:Architecture and Design:DESCRIPTION:Specific protection requirements depend strongly on contextual factors including the level of acceptable risk associated with compromise to the product's protection mechanism. Designers could incorporate anti-tampering measures that protect against or detect when the product has been tampered with.::PHASE:Testing:DESCRIPTION:The testing phase of the lifecycle should establish a method for determining whether the protection mechanism is sufficient to prevent unauthorized access.::PHASE:Manufacturing:DESCRIPTION:Ensure that all protection mechanisms are fully activated at the time of manufacturing and distribution.::,N/A
"Many high-performance on-chip bus protocols and processor data-paths employ separate channels for control and data to increase parallelism and maximize throughput. Bugs in the hardware logic that handle errors and security checks can make it possible for data to be forwarded before the completion of the security checks. If the data can propagate to a location in the hardware observable to an attacker, loss of data confidentiality can occur. 'Meltdown' is a concrete example of how de-synchronization between data and permissions checking logic can violate confidentiality requirements. Data loaded from a page marked as privileged was returned to the cpu regardless of current privilege level for performance reasons. The assumption was that the cpu could later remove all traces of this data during the handling of the illegal memory access exception, but this assumption was proven false as traces of the secret data were not removed from the microarchitectural state.",::NATURE:ChildOf:CWE ID:821:VIEW ID:1000:ORDINAL:Primary::NATURE:PeerOf:CWE ID:1037:VIEW ID:1000::,::PHASE:Architecture and Design:DESCRIPTION:Thoroughly verify the data routing logic to ensure that any error handling or security checks effectively block illegal dataflows.::,::REFERENCE:CVE-2017-5754:DESCRIPTION:Systems with microprocessors utilizing speculative execution and indirect branch prediction may allow unauthorized disclosure of information to an attacker with local user access via a side-channel analysis of the data cache.:LINK:https://www.cve.org/CVERecord?id=CVE-2017-5754::
"When a product is decommissioned - i.e., taken out of service - best practices or regulatory requirements may require the administrator to remove or overwrite sensitive data first, i.e. scrubbing. Improper scrubbing of sensitive data from a decommissioned device leaves that data vulnerable to acquisition by a malicious actor. Sensitive data may include, but is not limited to, device/manufacturer proprietary information, user/device credentials, network configurations, and other forms of sensitive data.",::NATURE:ChildOf:CWE ID:404:VIEW ID:1000:ORDINAL:Primary::,"::PHASE:Architecture and Design:DESCRIPTION:Functionality to completely scrub data from a product at the conclusion of its lifecycle should be part of the design phase. Trying to add this function on top of an existing architecture could lead to incomplete removal of sensitive information/data.::PHASE:Policy:DESCRIPTION:The manufacturer should describe the location(s) where sensitive data is stored and the policies and procedures for its removal. This information may be conveyed, for example, in an Administrators Guide or a Statement of Volatility.::PHASE:Implementation:DESCRIPTION:If the capability to wipe sensitive data isn't built-in, the manufacturer may need to provide a utility to scrub sensitive data from storage if that data is located in a place which is non-accessible by the administrator. One example of this could be when sensitive data is stored on an EEPROM for which there is no user/admin interface provided by the system.::",N/A
